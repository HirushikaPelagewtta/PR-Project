{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOYU5kyCIAiR51WB7AYl981",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HirushikaPelagewtta/PR-Project/blob/main/TransferLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install torch torchvision torchaudio scikit-learn\n"
      ],
      "metadata": {
        "id": "p9k8v-Wi0YR7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Imports & global config"
      ],
      "metadata": {
        "id": "CG2uCG7f367l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, copy, json, random, time\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, classification_report\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", DEVICE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwS0EdN10y4Y",
        "outputId": "87a715c5-29a4-4c7b-8aa1-da87da3359f0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Data (download EMNIST, split train→train/val, keep official test)"
      ],
      "metadata": {
        "id": "dY7bLjzz4Bij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Where to store/download EMNIST\n",
        "EMNIST_ROOT = \"./data\"     # this will create ./data and download under ./data/EMNIST/...\n",
        "os.makedirs(EMNIST_ROOT, exist_ok=True)\n",
        "\n",
        "# EMNIST split you asked for: 'mnist' (10 digits)\n",
        "EMNIST_SPLIT = \"mnist\"\n",
        "\n",
        "# We’ll make a validation set = 15% of the official TRAIN set\n",
        "VAL_FRACTION = 0.15\n",
        "\n",
        "# ImageNet-sized inputs for pretrained backbones\n",
        "IMG_SIZE = 224\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.RandomAffine(degrees=5, translate=(0.05,0.05), shear=5, scale=(0.95,1.05)),\n",
        "    transforms.Grayscale(num_output_channels=3),   # <-- convert L → RGB(3ch) while still PIL\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "\n",
        "eval_transform = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.Grayscale(num_output_channels=3),   # <-- same here\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
        "])\n",
        "\n",
        "\n",
        "# Download datasets\n",
        "full_train = datasets.EMNIST(\n",
        "    root=EMNIST_ROOT, split=EMNIST_SPLIT, train=True, download=True, transform=train_transform\n",
        ")\n",
        "test_ds = datasets.EMNIST(\n",
        "    root=EMNIST_ROOT, split=EMNIST_SPLIT, train=False, download=True, transform=eval_transform\n",
        ")\n",
        "\n",
        "# Stratified split on TRAIN → train/val\n",
        "y = np.array(full_train.targets) if hasattr(full_train, \"targets\") else np.array(full_train.labels)\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=VAL_FRACTION, random_state=SEED)\n",
        "train_idx, val_idx = next(sss.split(np.zeros_like(y), y))\n",
        "\n",
        "train_ds = Subset(full_train, train_idx)\n",
        "\n",
        "# validation should use eval_transform (no aug), so re-instantiate a base train dataset with eval_transform\n",
        "val_base = datasets.EMNIST(\n",
        "    root=EMNIST_ROOT, split=EMNIST_SPLIT, train=True, download=False, transform=eval_transform\n",
        ")\n",
        "val_ds = Subset(val_base, val_idx)\n",
        "\n",
        "# Class names and count\n",
        "class_names = list(full_train.classes)\n",
        "num_classes = len(class_names)\n",
        "print(f\"Classes ({num_classes}): {class_names}\")\n",
        "\n",
        "# DataLoaders\n",
        "BATCH_SIZE = 64\n",
        "NUM_WORKERS = 2\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EG91VtM04QM",
        "outputId": "ce25859a-3b82-4ccd-e712-592868cdc72b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 562M/562M [01:38<00:00, 5.70MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes (10): ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = next(iter(train_loader))\n",
        "print(xb.shape)  # should be [B, 3, 224, 224]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b389_ruw2q4c",
        "outputId": "0b6cb11e-27f5-4894-8a04-549cec1352b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Utilities (1→3 channels, train/eval loops, plots)"
      ],
      "metadata": {
        "id": "VBMzHZ3J4Gpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def maybe_to_rgb(x):\n",
        "    # EMNIST is [N,1,H,W]; pretrained nets expect 3 channels\n",
        "    if x.shape[1] == 1:\n",
        "        x = x.repeat(1, 3, 1, 1)\n",
        "    return x\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "    for imgs, labels in loader:\n",
        "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "        imgs = maybe_to_rgb(imgs)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * labels.size(0)\n",
        "        preds = outputs.argmax(1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    return running_loss/total, correct/total\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "    all_preds, all_targets = [], []\n",
        "    for imgs, labels in loader:\n",
        "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
        "        imgs = maybe_to_rgb(imgs)\n",
        "\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        running_loss += loss.item() * labels.size(0)\n",
        "        preds = outputs.argmax(1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        all_preds.append(preds.cpu().numpy())\n",
        "        all_targets.append(labels.cpu().numpy())\n",
        "\n",
        "    loss = running_loss/total\n",
        "    acc  = correct/total\n",
        "    y_pred = np.concatenate(all_preds)\n",
        "    y_true = np.concatenate(all_targets)\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=range(num_classes))\n",
        "    pr, rc, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)\n",
        "    return loss, acc, cm, pr, rc, f1\n",
        "\n",
        "def plot_history(hist, title):\n",
        "    epochs = range(1, len(hist[\"train_loss\"])+1)\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, hist[\"train_loss\"], label=\"train loss\")\n",
        "    plt.plot(epochs, hist[\"val_loss\"],   label=\"val loss\")\n",
        "    plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.title(title); plt.legend(); plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, [x*100 for x in hist[\"val_acc\"]], label=\"val acc (%)\")\n",
        "    plt.xlabel(\"epoch\"); plt.ylabel(\"accuracy %\"); plt.title(title); plt.legend(); plt.show()\n"
      ],
      "metadata": {
        "id": "ksUjSry_1G_l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Model factory (ResNet-18 / DenseNet-121)"
      ],
      "metadata": {
        "id": "kOhBlcby4K4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(arch: str, num_classes: int, pretrained=True, freeze_backbone=False):\n",
        "    arch = arch.lower()\n",
        "    if arch == \"resnet18\":\n",
        "        model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None)\n",
        "        in_feats = model.fc.in_features\n",
        "        model.fc = nn.Linear(in_feats, num_classes)\n",
        "        backbone = [p for n,p in model.named_parameters() if not n.startswith(\"fc.\")]\n",
        "    elif arch == \"densenet121\":\n",
        "        model = models.densenet121(weights=models.DenseNet121_Weights.IMAGENET1K_V1 if pretrained else None)\n",
        "        in_feats = model.classifier.in_features\n",
        "        model.classifier = nn.Linear(in_feats, num_classes)\n",
        "        backbone = [p for n,p in model.named_parameters() if not n.startswith(\"classifier\")]\n",
        "    else:\n",
        "        raise ValueError(\"Supported architectures: resnet18, densenet121\")\n",
        "\n",
        "    if freeze_backbone:\n",
        "        for p in backbone:\n",
        "            p.requires_grad = False\n",
        "    return model.to(DEVICE)\n",
        "\n",
        "def count_trainable_params(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
      ],
      "metadata": {
        "id": "88tPOfBk1KMe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Fine-tuning routine (head-only → unfreeze all)"
      ],
      "metadata": {
        "id": "y4jU3iEs4OKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def finetune(arch, epochs_head=5, epochs_full=10,\n",
        "             lr_head=1e-3, lr_full=2e-4, weight_decay=1e-4):\n",
        "    model = build_model(arch, num_classes, pretrained=True, freeze_backbone=True)\n",
        "    print(arch, \"head-only trainable params:\", count_trainable_params(model))\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Phase A: train classifier head\n",
        "    params_head = [p for p in model.parameters() if p.requires_grad]\n",
        "    opt = optim.AdamW(params_head, lr=lr_head, weight_decay=weight_decay)\n",
        "    sched = CosineAnnealingLR(opt, T_max=epochs_head)\n",
        "\n",
        "    history = {\"train_loss\":[], \"val_loss\":[], \"val_acc\":[]}\n",
        "    best_model = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(1, epochs_head+1):\n",
        "        tr_loss, tr_acc = train_one_epoch(model, train_loader, opt, criterion)\n",
        "        val_loss, val_acc, *_ = evaluate(model, val_loader, criterion)\n",
        "        history[\"train_loss\"].append(tr_loss)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "        sched.step()\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model = copy.deepcopy(model.state_dict())\n",
        "        print(f\"[{arch} | head] {epoch}/{epochs_head}  train_loss={tr_loss:.4f}  val_loss={val_loss:.4f}  val_acc={val_acc*100:.2f}%\")\n",
        "\n",
        "    # Phase B: unfreeze and fine-tune all\n",
        "    model.load_state_dict(best_model)\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = True\n",
        "    print(arch, \"full-train trainable params:\", count_trainable_params(model))\n",
        "\n",
        "    opt = optim.AdamW(model.parameters(), lr=lr_full, weight_decay=weight_decay)\n",
        "    sched = CosineAnnealingLR(opt, T_max=epochs_full)\n",
        "\n",
        "    for epoch in range(1, epochs_full+1):\n",
        "        tr_loss, tr_acc = train_one_epoch(model, train_loader, opt, criterion)\n",
        "        val_loss, val_acc, *_ = evaluate(model, val_loader, criterion)\n",
        "        history[\"train_loss\"].append(tr_loss)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "        sched.step()\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model = copy.deepcopy(model.state_dict())\n",
        "        print(f\"[{arch} | full] {epoch}/{epochs_full}  train_loss={tr_loss:.4f}  val_loss={val_loss:.4f}  val_acc={val_acc*100:.2f}%\")\n",
        "\n",
        "    model.load_state_dict(best_model)\n",
        "    return model, history\n"
      ],
      "metadata": {
        "id": "zrIbmaiq1M4s"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Train both SOTA models"
      ],
      "metadata": {
        "id": "oQZy11A-4Tcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models_histories = {}\n",
        "archs = [\"resnet18\", \"densenet121\"]\n",
        "\n",
        "for arch in archs:\n",
        "    model_ft, hist = finetune(arch,\n",
        "                              epochs_head=5, epochs_full=10,\n",
        "                              lr_head=1e-3, lr_full=2e-4,\n",
        "                              weight_decay=1e-4)\n",
        "    models_histories[arch] = {\"model\": model_ft, \"history\": hist}\n",
        "    plot_history(hist, f\"{arch} fine-tuning\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S44Jbrj41QnF",
        "outputId": "200088ef-2fba-40fe-f401-57ba44eee0bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 131MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "resnet18 head-only trainable params: 5130\n",
            "[resnet18 | head] 1/5  train_loss=0.6114  val_loss=0.3874  val_acc=89.48%\n",
            "[resnet18 | head] 2/5  train_loss=0.3076  val_loss=0.2822  val_acc=92.38%\n",
            "[resnet18 | head] 3/5  train_loss=0.2615  val_loss=0.2727  val_acc=92.41%\n",
            "[resnet18 | head] 4/5  train_loss=0.2448  val_loss=0.2474  val_acc=93.17%\n",
            "[resnet18 | head] 5/5  train_loss=0.2327  val_loss=0.2451  val_acc=93.26%\n",
            "resnet18 full-train trainable params: 11181642\n",
            "[resnet18 | full] 1/10  train_loss=0.0501  val_loss=0.0234  val_acc=99.28%\n",
            "[resnet18 | full] 2/10  train_loss=0.0282  val_loss=0.0163  val_acc=99.59%\n",
            "[resnet18 | full] 3/10  train_loss=0.0203  val_loss=0.0207  val_acc=99.40%\n",
            "[resnet18 | full] 4/10  train_loss=0.0162  val_loss=0.0156  val_acc=99.63%\n",
            "[resnet18 | full] 5/10  train_loss=0.0127  val_loss=0.0186  val_acc=99.50%\n",
            "[resnet18 | full] 6/10  train_loss=0.0099  val_loss=0.0170  val_acc=99.53%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def _predict_all(model, loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    for imgs, _ in loader:\n",
        "        imgs = maybe_to_rgb(imgs.to(DEVICE))\n",
        "        logits = model(imgs)\n",
        "        all_preds += logits.argmax(1).cpu().numpy().tolist()\n",
        "    return all_preds\n",
        "\n",
        "def evaluate_on_test(arch, model):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    test_loss, test_acc, cm, pr, rc, f1 = evaluate(model, test_loader, criterion)\n",
        "    print(f\"[{arch}] TEST  loss={test_loss:.4f}  acc={test_acc*100:.2f}%  macro-P/R/F1= {pr:.3f}/{rc:.3f}/{f1:.3f}\")\n",
        "    print(\"\\nPer-class report:\\n\", classification_report(\n",
        "        y_true=[y for _, y in test_ds],\n",
        "        y_pred=_predict_all(model, test_loader),\n",
        "        target_names=[str(c) for c in class_names],\n",
        "        zero_division=0))\n",
        "    return {\"loss\": test_loss, \"acc\": test_acc, \"cm\": cm, \"precision\": pr, \"recall\": rc, \"f1\": f1}\n",
        "\n",
        "results = {}\n",
        "for arch in archs:\n",
        "    res = evaluate_on_test(arch, models_histories[arch][\"model\"])\n",
        "    results[arch] = res\n"
      ],
      "metadata": {
        "id": "DtQ8dlBrHgcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add your custom CNN results here (from Part 1)\n",
        "custom_results = {\n",
        "    \"acc\":       0.00,  # e.g., 0.95\n",
        "    \"precision\": 0.00,\n",
        "    \"recall\":    0.00,\n",
        "    \"f1\":        0.00,\n",
        "}\n",
        "\n",
        "import pandas as pd\n",
        "rows = [{\"Model\": \"Custom CNN\", \"Test Acc\": custom_results[\"acc\"],\n",
        "         \"Precision\": custom_results[\"precision\"], \"Recall\": custom_results[\"recall\"], \"F1\": custom_results[\"f1\"]}]\n",
        "for arch in archs:\n",
        "    rows.append({\"Model\": arch,\n",
        "                 \"Test Acc\": results[arch][\"acc\"],\n",
        "                 \"Precision\": results[arch][\"precision\"],\n",
        "                 \"Recall\": results[arch][\"recall\"],\n",
        "                 \"F1\": results[arch][\"f1\"]})\n",
        "df_compare = pd.DataFrame(rows)\n",
        "df_compare\n"
      ],
      "metadata": {
        "id": "Yurh8OUYHtWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"outputs\", exist_ok=True)\n",
        "\n",
        "def save_cm(cm, fname, labels):\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(cm, interpolation='nearest')\n",
        "    plt.title(fname); plt.colorbar()\n",
        "    tick_marks = np.arange(len(labels))\n",
        "    plt.xticks(tick_marks, labels, rotation=90); plt.yticks(tick_marks, labels)\n",
        "    plt.tight_layout(); plt.ylabel('True'); plt.xlabel('Predicted')\n",
        "    fig.savefig(f\"outputs/{fname}.png\", bbox_inches='tight'); plt.close(fig)\n",
        "\n",
        "for arch in archs:\n",
        "    save_cm(results[arch][\"cm\"], f\"{arch}_confusion_matrix\", [str(c) for c in class_names])\n",
        "    with open(f\"outputs/{arch}_history.json\",\"w\") as f:\n",
        "        json.dump(models_histories[arch][\"history\"], f, indent=2, default=float)\n",
        "\n",
        "print(\"Saved confusion matrices and histories in ./outputs\")\n"
      ],
      "metadata": {
        "id": "KGHxbpMSHxBb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}