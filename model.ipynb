{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HirushikaPelagewtta/PR-Project/blob/main/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPWPtBFcR8mq"
      },
      "source": [
        "1. Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHy9_mI6R8mu",
        "outputId": "e30f78b2-ff95-44ab-da74-d1bcfdd498b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.5.1+cu121\n",
            "0.20.1+cu121\n",
            "1\n",
            "NVIDIA L4\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "# Import PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "# Import torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import torchvision.models as models\n",
        "from torchvision.models import EfficientNet_B0_Weights\n",
        "from torchvision.transforms import ToTensor, Resize, Normalize\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "# Import matplotlib for visualization\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from datetime import datetime\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "from torch.cuda.amp import GradScaler, autocast  # Import GradScaler and autocast\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Check versions\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj4oyyR7SHxX",
        "outputId": "046780f2-f9b4-49e5-a7a0-e003d474aae7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import tarfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsMNzYacSDSH",
        "outputId": "3bcc7958-e0c1-4e62-a36f-d1afaa8b58af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train real files extracted successfully!\n",
            "train fake Files extracted successfully!\n",
            "valid real Files extracted successfully!\n",
            "valid real Files extracted successfully!\n",
            "finish\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Define a directory to save the extracted files\n",
        "output_dir = './train'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "real=\"/content/drive/MyDrive/Colab Notebooks/SP Cup 2025/Dataset/Tar Files/train_real.tar\"\n",
        "with tarfile.open(real, 'r') as tar:\n",
        "    tar.extractall(path=output_dir)\n",
        "    print(\"train real files extracted successfully!\")\n",
        "\n",
        "output_dir = './train'\n",
        "fake=\"/content/drive/MyDrive/Colab Notebooks/SP Cup 2025/Dataset/Tar Files/train_fake.tar\"\n",
        "with tarfile.open(fake, 'r') as tar:\n",
        "    tar.extractall(path=output_dir)\n",
        "    print(\"train fake Files extracted successfully!\")\n",
        "\n",
        "output_dir = './valid'\n",
        "real=\"/content/drive/MyDrive/Colab Notebooks/SP Cup 2025/Dataset/Tar Files/valid_real.tar\"\n",
        "with tarfile.open(real, 'r') as tar:\n",
        "    tar.extractall(path=output_dir)\n",
        "    print(\"valid real Files extracted successfully!\")\n",
        "\n",
        "output_dir = './valid'\n",
        "fake=\"/content/drive/MyDrive/Colab Notebooks/SP Cup 2025/Dataset/Tar Files/valid_fake.tar\"\n",
        "with tarfile.open(fake, 'r') as tar:\n",
        "    tar.extractall(path=output_dir)\n",
        "    print(\"valid real Files extracted successfully!\")\n",
        "\n",
        "\n",
        "tar.close()\n",
        "\n",
        "print(\"finish\")\n",
        "\n",
        "train_dir = \"/content/train\"\n",
        "valid_dir = \"/content/valid\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umGogqW_R8mz"
      },
      "source": [
        "2. Set the Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H47rnsYs3p2M"
      },
      "outputs": [],
      "source": [
        "# prompt: clear gpu ram\n",
        "\n",
        "import torch\n",
        "\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZovGXwWR8mz"
      },
      "outputs": [],
      "source": [
        "# Paths to real and fake image directories\n",
        "train_real_path = \"/content/train/real\"\n",
        "train_fake_path =  \"/content/train/fake\"\n",
        "train_path =  \"/content/train\"\n",
        "\n",
        "test_real_path = \"/content/valid/real\"\n",
        "test_fake_path = \"/content/valid/fake\"\n",
        "test_path = \"/content/valid\"\n",
        "\n",
        "#Small Dataset\n",
        "#train_real_path = r\"D:\\Projects\\SP CUP Dataset\\valid\\real\" # r is because of the backslash causing \\p\n",
        "#train_fake_path = r\"D:\\Projects\\SP CUP Dataset\\valid\\fake\" # to be interpreted as a special character\n",
        "#test_real_path = r\"D:\\Projects\\SP CUP Dataset\\Small train\\real\"\n",
        "#test_fake_path = r\"D:\\Projects\\SP CUP Dataset\\Small train\\fake\"\n",
        "\n",
        "#Define the maximum number of samples per class\n",
        "TRAIN_MAX_SAMPLES_PER_CLASS = 50000  # Programmer-defined limit\n",
        "TEST_MAX_SAMPLES_PER_CLASS = 50000  # Programmer-defined limit\n",
        "\n",
        "BATCH_SIZE = 32 # Batch size for training\n",
        "#LR = 0.1 # Learning rate\n",
        "RANDOM_SEED = 42 # Seed for random number generator\n",
        "Visualize = False # Visualize the data\n",
        "\n",
        "#Define the classes\n",
        "classes = ['Fake', 'Real']\n",
        "Real_Index = 1\n",
        "Fake_Index = 0\n",
        "\n",
        "num_epochs = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0sDaIKcR8m0"
      },
      "source": [
        "✔ 1 for real and 0 for fake since classes = ['fake', 'real']\n",
        "fileID <TAB> score where fileID is the id of the test file, and score is a numerical value -- a higher value for real images and lower value for fake images.(from documentation)\n",
        "\n",
        "✔ The train_dataloader is created with shuffle=True to shuffle the training data at the beginning of each epoch. (not implemented )\n",
        "\n",
        "✔ The test_dataloader is created with shuffle=False to keep the order of the test data consistent.\n",
        "\n",
        "✔Read efficientnet documentation and act accordingly\n",
        "\n",
        "Way to save the model using checkpoints.\n",
        "\n",
        "Way to get std and mean of the provided dataset\n",
        "\n",
        "Apply regularization (Model markdown)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfi9El7oR8m1"
      },
      "source": [
        "3. Balanced Training and Testing Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2gqPSHFR8m2"
      },
      "outputs": [],
      "source": [
        "def display_total_filecount(real_path, fake_path):\n",
        "    print(f\"Number of real images: {len(os.listdir(real_path))}, \"\n",
        "          f\"Number of fake images: {len(os.listdir(fake_path))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B34XTkydR8m3",
        "outputId": "7605e743-e549-46a8-8ab4-3191d93fa673"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of real images: 42690, Number of fake images: 219470\n",
            "Number of real images: 1548, Number of fake images: 1524\n"
          ]
        }
      ],
      "source": [
        "display_total_filecount(train_real_path, train_fake_path)\n",
        "display_total_filecount(test_real_path, test_fake_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s6tiFIIR8m4"
      },
      "source": [
        "3.1 Create Balanced Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5TC-GrhR8m4",
        "outputId": "cc2b6dcd-0219-4f4a-b7d0-edd0cefbc330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total dataset size: 100000 (Real: 50000, Fake: 50000)\n"
          ]
        }
      ],
      "source": [
        "#random.seed(RANDOM_SEED)\n",
        "\n",
        "#Get the image filenames\n",
        "train_real_images = os.listdir(train_real_path)\n",
        "train_fake_images = os.listdir(train_fake_path)\n",
        "\n",
        "# Apply the limit\n",
        "train_real_images = train_real_images[:min(TRAIN_MAX_SAMPLES_PER_CLASS, len(train_real_images))]\n",
        "#train_fake_images = train_fake_images[:min(TRAIN_MAX_SAMPLES_PER_CLASS, len(train_fake_images))]\n",
        "#Added Choosing random to avoid training only for a sample of the 200000 images\n",
        "train_fake_images = random.sample(train_fake_images, min(TRAIN_MAX_SAMPLES_PER_CLASS, len(train_fake_images)))\n",
        "\n",
        "# Oversample real_images to match the number of fake_images\n",
        "if len(train_real_images) < len(train_fake_images):\n",
        "    train_real_images = random.choices(train_real_images, k=len(train_fake_images))\n",
        "\n",
        "# Combine and label the dataset\n",
        "train_balanced_dataset = [(os.path.join(train_real_path, img), Real_Index) for img in train_real_images] + \\\n",
        "                   [(os.path.join(train_fake_path, img), Fake_Index) for img in train_fake_images]\n",
        "\n",
        "# Shuffle the dataset\n",
        "random.shuffle(train_balanced_dataset)\n",
        "\n",
        "# Verify the limited dataset size\n",
        "print(f\"Total dataset size: {len(train_balanced_dataset)} (Real: {len(train_real_images)}, Fake: {len(train_fake_images)})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm4H9gYFR8m5",
        "outputId": "10731ff1-e29e-40d4-e127-0aadcffc2f60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total dataset size: 3072 (Real: 1548, Fake: 1524)\n"
          ]
        }
      ],
      "source": [
        "# Get the image filenames\n",
        "test_real_images = os.listdir(test_real_path)\n",
        "test_fake_images = os.listdir(test_fake_path)\n",
        "\n",
        "# Apply the limit\n",
        "test_real_images = test_real_images[:min(TEST_MAX_SAMPLES_PER_CLASS, len(test_real_images))]\n",
        "test_fake_images = test_fake_images[:min(TEST_MAX_SAMPLES_PER_CLASS, len(test_fake_images))]\n",
        "\n",
        "# Combine and label the dataset\n",
        "test_balanced_dataset = [(os.path.join(test_real_path, img), Real_Index) for img in test_real_images] + \\\n",
        "                   [(os.path.join(test_fake_path, img), Fake_Index) for img in test_fake_images]\n",
        "\n",
        "# Shuffle the dataset\n",
        "random.shuffle(test_balanced_dataset)\n",
        "\n",
        "# Verify the limited dataset size\n",
        "print(f\"Total dataset size: {len(test_balanced_dataset)} (Real: {len(test_real_images)}, Fake: {len(test_fake_images)})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6N7GVcXbXe-m"
      },
      "outputs": [],
      "source": [
        "def prepare_train_dataloader(train_real_path, train_fake_path, real_index, fake_index, max_samples_per_class):\n",
        "    \"\"\"\n",
        "    Prepare a balanced dataset with oversampled real images and randomly sampled fake images.\n",
        "\n",
        "    Args:\n",
        "        train_real_path (str): Path to the real images.\n",
        "        train_fake_path (str): Path to the fake images.\n",
        "        real_index (int): Label/index for real images.\n",
        "        fake_index (int): Label/index for fake images.\n",
        "        max_samples_per_class (int): Maximum number of samples per class for training.\n",
        "\n",
        "    Returns:\n",
        "        list: A balanced dataset as a list of tuples (image_path, label).\n",
        "    \"\"\"\n",
        "    # Get the image filenames\n",
        "    train_real_images = os.listdir(train_real_path)\n",
        "    train_fake_images = os.listdir(train_fake_path)\n",
        "\n",
        "    # Apply the limit to real and fake images\n",
        "    train_real_images = train_real_images[:min(max_samples_per_class, len(train_real_images))]\n",
        "    train_fake_images = random.sample(train_fake_images, min(max_samples_per_class, len(train_fake_images)))\n",
        "\n",
        "    # Oversample real images to match the number of fake images\n",
        "    if len(train_real_images) < len(train_fake_images):\n",
        "        train_real_images = random.choices(train_real_images, k=len(train_fake_images))\n",
        "\n",
        "    # Combine and label the dataset\n",
        "    train_balanced_dataset = [\n",
        "        (os.path.join(train_real_path, img), real_index) for img in train_real_images\n",
        "    ] + [\n",
        "        (os.path.join(train_fake_path, img), fake_index) for img in train_fake_images\n",
        "    ]\n",
        "\n",
        "    # Shuffle the dataset\n",
        "    random.shuffle(train_balanced_dataset)\n",
        "\n",
        "    # Print the dataset size for verification\n",
        "    print(f\"Total dataset size: {len(train_balanced_dataset)} (Real: {len(train_real_images)}, Fake: {len(train_fake_images)})\")\n",
        "\n",
        "    train_mean, train_std = [0.4598, 0.3929, 0.3792], [0.2327, 0.2046, 0.2103]\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize(224, interpolation=InterpolationMode.BICUBIC),  # First resize to 256\n",
        "        transforms.RandomHorizontalFlip(p=0.5),  # Flip image horizontally with 50% probability\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=train_mean, std=train_std)\n",
        "    ])\n",
        "\n",
        "    #Create the dataset\n",
        "    train_data = ImageDataset(train_balanced_dataset,\n",
        "                              transform=train_transform)\n",
        "\n",
        "    # Create the DataLoader\n",
        "    train_dataloader = DataLoader(train_data,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            shuffle=True,\n",
        "                            pin_memory=True)\n",
        "\n",
        "    return train_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKffTHPTR8m6"
      },
      "source": [
        "3.2 Visualize balanced datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQUEW9CER8m7"
      },
      "outputs": [],
      "source": [
        "def display_random_images(dataset, num_images):\n",
        "    # Set the random seed for reproducibility\n",
        "    random.seed(RANDOM_SEED)\n",
        "\n",
        "    # Randomly select num_images from the dataset\n",
        "    selected_indices = random.sample(range(len(dataset)), num_images)\n",
        "\n",
        "    # Create a figure with subplots\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(20, 8))  # Adjust the figsize as needed\n",
        "\n",
        "    for i, idx in enumerate(selected_indices):\n",
        "        image_path, label = dataset[idx]\n",
        "        image = Image.open(image_path)\n",
        "\n",
        "        # Display the image\n",
        "        axes[i].imshow(image)\n",
        "        axes[i].set_title(f\"Label: {'Real' if label == Real_Index else 'Fake'}\")\n",
        "        axes[i].set_xlabel(os.path.basename(image_path))  # Display the image name\n",
        "        axes[i].axis('off')  # Hide the axis\n",
        "\n",
        "        # Print the image file name and shape\n",
        "        print(f\"Image file name: {os.path.basename(image_path)}\")\n",
        "        print(f\"Image Shape: {image.size}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage with train_balanced_dataset and a seed value\n",
        "if Visualize==True:\n",
        "    display_random_images(train_balanced_dataset, num_images=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB4LxJM9R8m7"
      },
      "source": [
        "4. Transformed Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R125S3Z3R8m8"
      },
      "source": [
        "4.1 Image Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHN0aZdFR8m8"
      },
      "outputs": [],
      "source": [
        "# Define the dataset class\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        super().__init__()  # Call the parent class's init method\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.data[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEt3Bf6aR8m9"
      },
      "source": [
        "4.2 Finding out mean and std to use in the transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNaPzgRzR8m9"
      },
      "outputs": [],
      "source": [
        "def compute_mean_and_std_from_dataset(dataset, device='cuda'):\n",
        "    \"\"\"\n",
        "    Compute per-channel mean and std of the dataset (to be used in transforms.Normalize())\n",
        "    Args:\n",
        "        dataset (list): List of tuples containing image paths and labels.\n",
        "        device (str): Device to perform computations on ('cuda' or 'cpu').\n",
        "    Returns:\n",
        "        mean (list): List of mean values for each channel.\n",
        "        std (list): List of standard deviation values for each channel.\n",
        "    \"\"\"\n",
        "    # Initialize variables to store the sum and sum of squares of pixel values\n",
        "    mean = torch.zeros(3).to(device)\n",
        "    std = torch.zeros(3).to(device)\n",
        "    num_images = len(dataset)\n",
        "\n",
        "    for img_path, _ in tqdm(dataset, desc=\"Computing mean and std\"):\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        image = transforms.ToTensor()(image).to(device)\n",
        "\n",
        "        mean += image.mean(dim=(1, 2))\n",
        "        std += image.std(dim=(1, 2))\n",
        "\n",
        "    mean /= num_images\n",
        "    std /= num_images\n",
        "\n",
        "    mean = [round(m.item(), 4) for m in mean]\n",
        "    std = [round(s.item(), 4) for s in std]\n",
        "\n",
        "    return mean, std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smwRdgFiR8m9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Example usage\n",
        "#train_mean, train_std = compute_mean_and_std_from_dataset(train_balanced_dataset)\n",
        "#print(f\"Train Mean: {train_mean}, Train Std: {train_std}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rpXm3x5R8m-"
      },
      "outputs": [],
      "source": [
        "#test_mean, test_std = compute_mean_and_std_from_dataset(test_balanced_dataset)\n",
        "#print(f\"Test Mean: {test_mean}, Test Std: {test_std}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzVXltSMR8m-"
      },
      "source": [
        "4.3 Create transformed datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-oP_3w9R8m-",
        "outputId": "d4761734-e8d2-477f-d79c-6f3339e7e31f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image label: 1, Class name: Real\n"
          ]
        }
      ],
      "source": [
        "train_mean, train_std = [0.4598, 0.3929, 0.3792], [0.2327, 0.2046, 0.2103]\n",
        "test_mean, test_std = [0.3996, 0.3194, 0.3223], [0.2272, 0.1706, 0.1718]\n",
        "\n",
        "#train_mean, train_std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
        "#test_mean, test_std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
        "\n",
        "#This transform has better accuracy than the one below\n",
        "# Define transforms\n",
        "#transform = transforms.Compose([\n",
        "#    Resize((224, 224)),\n",
        "#    ToTensor(),\n",
        "#    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "#])\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(224, interpolation=InterpolationMode.BICUBIC),  # First resize to 256\n",
        "    #transforms.CenterCrop(224),  # Then center crop to 224\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # Flip image horizontally with 50% probability\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=train_mean.tolist(), std=train_std.tolist())\n",
        "\n",
        "    #transforms.ColorJitter(\n",
        "    #                brightness=0.2,      # Random brightness adjustment\n",
        "    #                contrast=0.2,        # Random contrast adjustment\n",
        "    #                saturation=0.2,      # Random saturation adjustment\n",
        "    #                hue=0.1             # Random hue adjustment\n",
        "    #            ),\n",
        "\n",
        "    transforms.Normalize(mean=train_mean, std=train_std)\n",
        "\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224, interpolation=InterpolationMode.BICUBIC),  # First resize to 256\n",
        "    #transforms.CenterCrop(224),  # Then center crop to 224\n",
        "    transforms.ToTensor(),\n",
        "    #transforms.Normalize(mean=test_mean.tolist(), std=test_std.tolist())\n",
        "    transforms.Normalize(mean=test_mean, std=test_std)\n",
        "])\n",
        "\n",
        "train_data = ImageDataset(train_balanced_dataset,\n",
        "                        transform=train_transform)\n",
        "\n",
        "#Create the dataset\n",
        "test_data = ImageDataset(test_balanced_dataset,\n",
        "                        transform=test_transform)\n",
        "\n",
        "# Example: Print the class name of a label\n",
        "for image, label in test_data:\n",
        "    class_name = classes[label]\n",
        "    print(f\"Image label: {label}, Class name: {class_name}\")\n",
        "    break  # Just print the first one for demonstration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WEa8vSAR8m_"
      },
      "source": [
        "4.4 Visualize transformed datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQCg-1x8R8m_"
      },
      "outputs": [],
      "source": [
        "def unnormalize(tensor, mean, std):\n",
        "    \"\"\"\n",
        "    Unnormalize a tensor image.\n",
        "    Args:\n",
        "        tensor (torch.Tensor): The normalized tensor image.\n",
        "        mean (torch.Tensor): The mean used for normalization.\n",
        "        std (torch.Tensor): The standard deviation used for normalization.\n",
        "    Returns:\n",
        "        torch.Tensor: The unnormalized tensor image.\n",
        "    \"\"\"\n",
        "    tensor = tensor.clone()  # Clone the tensor to avoid modifying the original\n",
        "    for t, m, s in zip(tensor, mean, std):\n",
        "        t.mul_(s).add_(m)  # Unnormalize\n",
        "    return tensor\n",
        "\n",
        "def plot_random_images(dataset, transform, num_images):\n",
        "    random.seed(RANDOM_SEED)\n",
        "\n",
        "    # Randomly select num_images from the dataset\n",
        "    selected_indices = random.sample(range(len(dataset)), num_images)\n",
        "\n",
        "    # Display num_images before and after transform\n",
        "    fig, axes = plt.subplots(3, num_images, figsize=(20, 8))  # 2 rows, num_images columns\n",
        "\n",
        "    for i, idx in enumerate(selected_indices):\n",
        "        image_path, label = dataset[idx]\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "        # Display original image\n",
        "        axes[0, i].imshow(image)\n",
        "        axes[0, i].set_title(f\"Original\\nLabel: {'Real' if label == Real_Index else 'Fake'}\")\n",
        "        axes[0, i].axis('off')  # Hide the axis\n",
        "\n",
        "        # Apply transform and display transformed image\n",
        "        transformed_image = transform(image)\n",
        "        axes[1, i].imshow(transformed_image.permute(1, 2, 0))  # Display the transformed image\n",
        "        axes[1, i].set_title(f\"Transformed\\nLabel: {'Real' if label == Real_Index else 'Fake'}\")\n",
        "        axes[1, i].axis('off')  # Hide the axis\n",
        "\n",
        "        # Unnormalize and display the unnormalized image\n",
        "        unnormalized_image = unnormalize(transformed_image, train_mean, train_std)\n",
        "        axes[2, i].imshow(unnormalized_image.permute(1, 2, 0))  # Unnormalize the image\n",
        "        axes[2, i].set_title(f\"Unnormalized\\nLabel: {'Real' if label == Real_Index else 'Fake'}\")\n",
        "        axes[2, i].axis('off')  # Hide the axis\n",
        "\n",
        "        # Print the transformed image shape and label\n",
        "        print(transformed_image.shape, label)\n",
        "        print(f\"Image file name: {image_path}\")\n",
        "        print(f\"Image label: {[label]}\")\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage with train_balanced_dataset and train_transform\n",
        "if Visualize==True:\n",
        "    plot_random_images(train_balanced_dataset, train_transform, num_images=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlZeKR-uR8m_"
      },
      "source": [
        "5. DataLoaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk69O21JR8nA"
      },
      "source": [
        "5.1 Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bf422P4DR8nA"
      },
      "outputs": [],
      "source": [
        "# Create the DataLoader\n",
        "train_dataloader = DataLoader(train_data,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(test_data,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iygSc2xdR8nA"
      },
      "source": [
        "5.2 Visualize DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdEGlRvIR8nA",
        "outputId": "29dd01f9-5ca4-4bd4-a024-16da0980ba0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 3, 224, 224]) torch.Size([32])\n",
            "torch.Size([3, 224, 224])\n",
            "DataLoaders: (<torch.utils.data.dataloader.DataLoader object at 0x7c75826f2860>, <torch.utils.data.dataloader.DataLoader object at 0x7c75826f0430>)\n",
            "Length of train_dataloader: 3125 batches of 32... = 100000\n",
            "Length of test_dataloader: 96 batches of 32... = 3072\n"
          ]
        }
      ],
      "source": [
        "# Example: Iterate through the DataLoader\n",
        "for images, labels in test_dataloader:\n",
        "    print(images.shape, labels.shape)\n",
        "    break\n",
        "\n",
        "print(images[0].shape)\n",
        "\n",
        "\n",
        "# Let's check out what what we've created\n",
        "print(f\"DataLoaders: {train_dataloader, test_dataloader}\")\n",
        "print(f\"Length of train_dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}... = {BATCH_SIZE*len(train_dataloader)}\")\n",
        "print(f\"Length of test_dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}... = {BATCH_SIZE*len(test_dataloader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EMBLTOJR8nB"
      },
      "source": [
        "6. Building a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSPsYYp1R8nB"
      },
      "source": [
        "6.0 Model_v0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtQpryJIR8nB"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained EfficientNet-B6 model\n",
        "class DeepFakeDetectV0(nn.Module):\n",
        "    def __init__(self, output_shape: int):\n",
        "        super(DeepFakeDetectV0, self).__init__()\n",
        "        # Load pre-trained EfficientNet-B6 model\n",
        "        self.efficientnet = models.efficientnet_b6(weights=models.EfficientNet_B6_Weights.IMAGENET1K_V1)\n",
        "\n",
        "        # Unfreeze more layers\n",
        "        for param in self.efficientnet.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        # Replace the final fully connected layer\n",
        "        num_ftrs = self.efficientnet.classifier[1].in_features\n",
        "        self.efficientnet.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=0.5, inplace=True),  # Adjusted dropout rate for EfficientNet-B6\n",
        "            nn.Linear(num_ftrs, output_shape)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.efficientnet(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-OgyRiemnGh"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained EfficientNet model\n",
        "#class DeepFakeDetectV0(nn.Module):\n",
        "#   def __init__(self, output_shape: int):\n",
        "#       super(DeepFakeDetectV0, self).__init__()\n",
        "#       # Load pre-trained EfficientNet model\n",
        "#       self.efficientnet = models.efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "#\n",
        "#       # Unfreeze more layers\n",
        "#       for param in self.efficientnet.parameters():\n",
        "#           param.requires_grad = True\n",
        "#\n",
        "#       # Replace the final fully connected layer\n",
        "#       num_ftrs = self.efficientnet.classifier[1].in_features\n",
        "#       self.efficientnet.classifier = nn.Sequential(\n",
        "#           nn.Dropout(p=0.2, inplace=True),\n",
        "#           nn.Linear(num_ftrs, output_shape)\n",
        "#       )\n",
        "#\n",
        "#   def forward(self, x):\n",
        "#       return self.efficientnet(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYxHPufrR8nB"
      },
      "source": [
        "7. Setup the model for the first time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7Dlsw27R8nB",
        "outputId": "4ed3bd1f-ba48-4ccb-dea4-89a88f564232"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b6_lukemelas-24a108a5.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b6_lukemelas-24a108a5.pth\n",
            "100%|██████████| 165M/165M [00:00<00:00, 210MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model is on device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model_0 = DeepFakeDetectV0(output_shape=1)\n",
        "model_0.to(device)\n",
        "\n",
        "# Check the device of the model\n",
        "model_0_device = next(model_0.parameters()).device\n",
        "print(f\"Model is on device: {model_0_device}\")\n",
        "#model_0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_hOnMWwR8nB"
      },
      "source": [
        "7.1 Visualize Model's Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMjoPV5eR8nB"
      },
      "outputs": [],
      "source": [
        "if Visualize == True:\n",
        "    # Test with random tensor (batch_size=32, channels=3, height=224, width=224)\n",
        "    test_input = torch.randn(32, 3, 224, 224).to(device)\n",
        "    output = model_0(test_input)\n",
        "    print(f\"Input shape: {test_input.shape}\")\n",
        "    print(f\"Output shape: {output.shape}\")\n",
        "    print(f\"Sample predictions:\\n{output[:5].cpu().detach().numpy()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNTHEmhdR8nB"
      },
      "source": [
        "7.2 Check the State Dictionary of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5v92xB4uR8nB"
      },
      "outputs": [],
      "source": [
        "if Visualize == True:\n",
        "    print(model_0.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwDZJ2fYR8nC"
      },
      "source": [
        "7.3 Further Checking the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctgxEN9zR8nK"
      },
      "outputs": [],
      "source": [
        "if Visualize == True:\n",
        "    # Iterate through the test_dataloader and print the first 5 values\n",
        "    for i, (images, labels) in enumerate(test_dataloader):\n",
        "        if i < 1:\n",
        "            print(f\"Batch {i+1}:\")\n",
        "            print(f\"Images: {images}\")\n",
        "            print(f\"Labels: {labels}\")\n",
        "        else:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFmiNDhPR8nK"
      },
      "outputs": [],
      "source": [
        "if Visualize == True:\n",
        "    # View the first 5 outputs of the forward pass on the test data\n",
        "    model_0.eval()\n",
        "    with torch.inference_mode():\n",
        "      for X_test, y_test in test_dataloader:\n",
        "        X_test, y_test = X_test.to(device), y_test.to(device)  # Move tensors to the same device as the model\n",
        "        # 1. Forward pass\n",
        "        y_logits = model_0(X_test.to(device))[:5]\n",
        "        break\n",
        "\n",
        "    print(\"y_logits \",y_logits)\n",
        "    print(\"y_test \", y_test[:5])\n",
        "\n",
        "    # Use the sigmoid activation function on our model logits to turn them into prediction probabilities\n",
        "    y_pred_probs = torch.sigmoid(y_logits)\n",
        "    print(\"y_pred_probs \",y_pred_probs)\n",
        "    # Find the predicted labels\n",
        "    y_preds = torch.round(y_pred_probs)\n",
        "\n",
        "    # Convert the tensor to a list of labels\n",
        "    y_pred_labels = [classes[int(label)] for label in y_preds]\n",
        "\n",
        "    print(y_pred_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLPhmLO0R8nL"
      },
      "source": [
        "8. Setup Loss, Optimizer and evaluation metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmNUOI1qR8nL"
      },
      "source": [
        "8.1 Setup Loss and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSxbiknPR8nL"
      },
      "outputs": [],
      "source": [
        "# Setup loss function and optimizer\n",
        "#loss_fn = nn.BCEWithLogitsLoss()\n",
        "#optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
        "                            #lr=0.01)\n",
        "# Define the optimizer\n",
        "#optimizer = optim.Adam(model_0.parameters(), lr=LR)\n",
        "\n",
        "# Define the learning rate scheduler\n",
        "#scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "# Setup loss function and optimizer\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "\n",
        "#Define optimizer with initial learning rate\n",
        "initial_lr = 1e-6  # EfficientNet often works well with lower learning rates\n",
        "optimizer = optim.Adam(model_0.parameters(), lr=initial_lr)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optimizer,\n",
        "    T_max=num_epochs,\n",
        "    eta_min=initial_lr/100,  # This will automatically adjust based on your initial_lr\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC_4ArJ0R8nL"
      },
      "source": [
        "8.2 Function to time our experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj3okzpnR8nL",
        "outputId": "b62a2e8e-3760-43d4-90c5-6221c6c38a61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train time on cpu: 0.000 seconds\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "2.1846999970875913e-05"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from timeit import default_timer as timer\n",
        "def print_train_time(start: float,\n",
        "                     end: float,\n",
        "                     device: torch.device = None):\n",
        "  \"\"\"Prints difference between start and end time.\"\"\"\n",
        "  total_time = end - start\n",
        "  print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "  return total_time\n",
        "\n",
        "start_time = timer()\n",
        "# some code...\n",
        "end_time = timer()\n",
        "print_train_time(start=start_time, end=end_time, device=\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRHzQTwtR8nL"
      },
      "source": [
        "8.3 Accuracy Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pu5JJgfR8nM"
      },
      "outputs": [],
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "  correct = torch.eq(y_true, y_pred).sum().item()\n",
        "  acc = (correct/len(y_pred)) * 100\n",
        "  return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "addXxvLeR8nM",
        "outputId": "dda22925-1890-4edf-ffb8-01e3a44aa7d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-30-653d56c8f7c4>:2: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=True)\n"
          ]
        }
      ],
      "source": [
        "# Initialize GradScaler for mixed precision training\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqBlnaL4XvqT"
      },
      "outputs": [],
      "source": [
        "#torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UW7BqAQCnLqQ"
      },
      "outputs": [],
      "source": [
        "def prepare_train_dataloader(train_real_path, train_fake_path, real_index, fake_index, max_samples_per_class):\n",
        "    \"\"\"\n",
        "    Prepare a balanced dataset with oversampled real images and randomly sampled fake images.\n",
        "\n",
        "    Args:\n",
        "        train_real_path (str): Path to the real images.\n",
        "        train_fake_path (str): Path to the fake images.\n",
        "        real_index (int): Label/index for real images.\n",
        "        fake_index (int): Label/index for fake images.\n",
        "        max_samples_per_class (int): Maximum number of samples per class for training.\n",
        "\n",
        "    Returns:\n",
        "        list: A balanced dataset as a list of tuples (image_path, label).\n",
        "    \"\"\"\n",
        "    # Get the image filenames\n",
        "    train_real_images = os.listdir(train_real_path)\n",
        "    train_fake_images = os.listdir(train_fake_path)\n",
        "\n",
        "    # Apply the limit to real and fake images\n",
        "    train_real_images = train_real_images[:min(max_samples_per_class, len(train_real_images))]\n",
        "    train_fake_images = random.sample(train_fake_images, min(max_samples_per_class, len(train_fake_images)))\n",
        "\n",
        "    # Oversample real images to match the number of fake images\n",
        "    if len(train_real_images) < len(train_fake_images):\n",
        "        train_real_images = random.choices(train_real_images, k=len(train_fake_images))\n",
        "\n",
        "    # Combine and label the dataset\n",
        "    train_balanced_dataset = [\n",
        "        (os.path.join(train_real_path, img), real_index) for img in train_real_images\n",
        "    ] + [\n",
        "        (os.path.join(train_fake_path, img), fake_index) for img in train_fake_images\n",
        "    ]\n",
        "\n",
        "    # Shuffle the dataset\n",
        "    random.shuffle(train_balanced_dataset)\n",
        "\n",
        "    # Print the dataset size for verification\n",
        "    print(f\"Total dataset size: {len(train_balanced_dataset)} (Real: {len(train_real_images)}, Fake: {len(train_fake_images)})\")\n",
        "\n",
        "    train_mean, train_std = [0.4598, 0.3929, 0.3792], [0.2327, 0.2046, 0.2103]\n",
        "\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize(224, interpolation=InterpolationMode.BICUBIC),  # First resize to 256\n",
        "        transforms.RandomHorizontalFlip(p=0.5),  # Flip image horizontally with 50% probability\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=train_mean, std=train_std)\n",
        "    ])\n",
        "\n",
        "    #Create the dataset\n",
        "    train_data = ImageDataset(train_balanced_dataset,\n",
        "                              transform=train_transform)\n",
        "\n",
        "    # Create the DataLoader\n",
        "    train_dataloader = DataLoader(train_data,\n",
        "                            batch_size=BATCH_SIZE,\n",
        "                            shuffle=True,\n",
        "                            pin_memory=True)\n",
        "\n",
        "    return train_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW_Kgk0zR8nM"
      },
      "source": [
        "9. Creating a Training loop and training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 688,
          "referenced_widgets": [
            "13096578798942079abe7138af80f6c5",
            "5650194f9174481185ea9aa6d0ec2d84",
            "18163ba627284ed083ec5bfd7b60d839",
            "3237bdbd33414cfd9c2d51ba5ebd8969",
            "17317583e5b54db5b44d2c1b9300f4a6",
            "68747309c2534f8bbb40c15ec7f4b661",
            "d410aacb950449118ec6b214c49f9e22",
            "81e21ea4dbf84848a518aeb5ce7acfd6",
            "1a116fe516044870a5c85e6850811342",
            "509f9993a8b641849c644ff9edad1d48",
            "7cf4e17cad5a4e47b7e3ab2c9edcceb3",
            "517fd7fc718d47a8be7cd0da0b362669",
            "87ecee2159974eca9572a80a4ee2086e",
            "265827331d104b39aa47a120b7208088",
            "6a99639681e84660b36b22a2aae1606c",
            "9bba19571fc74362b9eba466624aef6e",
            "92f6061a150b4cfd8446d12e1ab7771a",
            "125da04131e84e81bd01f7bf993a846b",
            "8a51f694453844878627a447b62f7a3b",
            "aaaeaec4d0594b73a46fb923228b93dd",
            "2ebd67217b60454e868aa09039429f0c",
            "a9f963f0bd464dcab33f2d1ed44b4805",
            "6dc2caa925aa41d583810adaf9a604ba",
            "5d6d3797d6c04b698b67dffb5026e70a",
            "30f59b7f6ec6415696f0d3ac4b104e23",
            "1a6428c89e204c85972fdbb89154fba6",
            "e90707b157cd4a08aa0ab9a2b19fc119",
            "5ca7b95912da463b9e246f3ba0b218c0",
            "084df3c94bde4e5c85fdb93d5cfd38f4",
            "c50633a05acb43299cf6059ad5a37d2f",
            "0b6dd921cf7f41ec862b99dd1addd242",
            "3b49379076ed41f6834a2f2b359e0a13",
            "ce32a36c71284ea3ba4196dfdee638ac"
          ]
        },
        "id": "R9DegJOuR8nM",
        "outputId": "b6254c8a-63dc-4861-b3a4-c2b7325bff93"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13096578798942079abe7138af80f6c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "------\n",
            "Total dataset size: 100000 (Real: 50000, Fake: 50000)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "517fd7fc718d47a8be7cd0da0b362669",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-24284ae680fd>:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 0 loss: 0.7133671045303345\n",
            "Batch 400 loss: 0.6998666524887085\n",
            "Batch 800 loss: 0.6814330816268921\n",
            "Batch 1200 loss: 0.6812651753425598\n",
            "Batch 1600 loss: 0.6877659559249878\n",
            "Batch 2000 loss: 0.7312932014465332\n",
            "Batch 2400 loss: 0.6414742469787598\n",
            "Batch 2800 loss: 0.6759970784187317\n",
            "\n",
            "Train loss: 0.6778\n",
            "Cumulative training accuracy: 0.57344\n",
            "Real images identified as real: 927\n",
            "Real images identified as fake: 597\n",
            "Fake images identified as real: 715\n",
            "Fake images identified as fake: 833\n",
            "\n",
            "Real images Total: 1524 | Fake images Total: 1548\n",
            "\n",
            "Test loss: 0.6715, Test acc: 0.5729\n",
            "Model saved to deepfake_detect_model_20250113_210444.pth\n",
            "Train loss: 0.6778 | Train acc: 57.3440% | Test loss: 0.6715 | Test acc: 57.2917%\n",
            "Epoch: 1\n",
            "------\n",
            "Total dataset size: 100000 (Real: 50000, Fake: 50000)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6dc2caa925aa41d583810adaf9a604ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3125 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch 0 loss: 0.6726198196411133\n",
            "Batch 400 loss: 0.6189436912536621\n",
            "Batch 800 loss: 0.5984528064727783\n"
          ]
        }
      ],
      "source": [
        "# Set the seed and start the timer\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "random.seed(42)\n",
        "train_time_start_on_cpu = timer()\n",
        "\n",
        "# Set the number of epochs (we'll keep this small for faster training time)\n",
        "epochs = num_epochs\n",
        "\n",
        "# Create training and test loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n------\")\n",
        "\n",
        "  ### Training\n",
        "  train_loss, train_acc = 0, 0\n",
        "  batch_accuracy = 0\n",
        "\n",
        "  train_dataloader = prepare_train_dataloader(train_real_path, train_fake_path, Real_Index, Fake_Index, TRAIN_MAX_SAMPLES_PER_CLASS)\n",
        "  # Add a loop to loop through the training batches\n",
        "  for batch, (X, y) in enumerate(tqdm(train_dataloader)):\n",
        "    # Put data to target device\n",
        "    X, y = X.to(device), y.float().to(device)\n",
        "\n",
        "    model_0.train()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    with torch.cuda.amp.autocast():\n",
        "        # 1. Forward pass\n",
        "        y_pred = model_0(X).squeeze()\n",
        "        #print(y_pred.type)\n",
        "        #print(y_pred[0])\n",
        "\n",
        "        # 2. Calculate loss (per batch)\n",
        "        loss = loss_fn(y_pred.view(-1), y.float())\n",
        "        if batch % 400 == 0:\n",
        "          print(f\"Batch {batch} loss: {loss.item()}\")\n",
        "\n",
        "    train_loss += loss.item() # accumulate train loss\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    #optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward\n",
        "    #loss.backward()\n",
        "    scaler.scale(loss).backward()\n",
        "\n",
        "    # 5. Optimizer step (update the model's parameters once *per batch*)\n",
        "    optimizer.step()\n",
        "    #scaler.step(optimizer)\n",
        "    #scaler.update()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Calculate accuracy\n",
        "        y_pred_class = torch.round(torch.sigmoid(y_pred))\n",
        "        #print(y_pred_class)\n",
        "        #print(y_pred_class.view(-1))\n",
        "        batch_accuracy = (y_pred_class.view(-1) == y).sum().item() / len(y_pred_class)\n",
        "        #print(f\"Batch accuracy: {batch_accuracy}\")\n",
        "\n",
        "        # Accumulate the batch accuracy to the training accuracy\n",
        "        train_acc += batch_accuracy\n",
        "        #print(f\"Cumulative training accuracy: {train_acc}\")\n",
        "\n",
        "  # Divide total train loss by length of train dataloader\n",
        "  train_loss /= len(train_dataloader)\n",
        "  train_acc /= len(train_dataloader)\n",
        "\n",
        "  print(f\"\\nTrain loss: {train_loss:.4f}\")\n",
        "  print(f\"Cumulative training accuracy: {train_acc}\")\n",
        "\n",
        "  ### Testing\n",
        "  test_loss, correct_predictions, total_predictions = 0, 0, 0\n",
        "  real_as_real, real_as_fake, fake_as_real, fake_as_fake = 0, 0, 0, 0\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "      for i, (X_test, y_test) in enumerate(test_dataloader):\n",
        "          # Put data to target device\n",
        "          X_test, y_test = X_test.to(device), y_test.float().to(device)\n",
        "\n",
        "          # 1. Forward pass\n",
        "          test_pred = model_0(X_test).squeeze()\n",
        "\n",
        "          # 2. Calculate loss (accumulatively)\n",
        "          test_loss += loss_fn(test_pred, y_test.float()).item()\n",
        "\n",
        "          # 3. Calculate accuracy\n",
        "          test_pred_class = torch.round(torch.sigmoid(test_pred))\n",
        "          correct_predictions += (test_pred_class.view(-1) == y_test).sum().item()\n",
        "          total_predictions += len(y_test)\n",
        "\n",
        "          # Print image names and predictions\n",
        "          for j in range(len(X_test)):\n",
        "              image_index = i * test_dataloader.batch_size + j\n",
        "              image_name = test_dataloader.dataset.data[image_index][0]\n",
        "              true_label = test_dataloader.dataset.data[image_index][1]\n",
        "              predicted_label = test_pred_class[j].item()\n",
        "              #print(f\"Image: {image_name}, True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
        "              #print(f\"Image: {image_name}, True Label: {classes[int(true_label)]}, Predicted Label: {classes[int(predicted_label)]}\")\n",
        "\n",
        "              if true_label == 0 and predicted_label == 0:\n",
        "                  real_as_real += 1\n",
        "              elif true_label == 0 and predicted_label == 1:\n",
        "                  real_as_fake += 1\n",
        "              elif true_label == 1 and predicted_label == 0:\n",
        "                  fake_as_real += 1\n",
        "              elif true_label == 1 and predicted_label == 1:\n",
        "                  fake_as_fake += 1\n",
        "              #print(real_as_real, real_as_fake, fake_as_real, fake_as_fake)\n",
        "\n",
        "      # Calculate the test loss average per batch\n",
        "      test_loss /= len(test_dataloader)\n",
        "\n",
        "      # Calculate the test accuracy\n",
        "      #test_acc = correct_predictions / total_predictions\n",
        "      test_acc = (real_as_real + fake_as_fake) / (real_as_real + real_as_fake + fake_as_real + fake_as_fake)\n",
        "      print(f\"Real images identified as real: {real_as_real}\")\n",
        "      print(f\"Real images identified as fake: {real_as_fake}\")\n",
        "      print(f\"Fake images identified as real: {fake_as_real}\")\n",
        "      print(f\"Fake images identified as fake: {fake_as_fake}\")\n",
        "      print(f\"\\nReal images Total: {real_as_real + real_as_fake} | Fake images Total: {fake_as_real + fake_as_fake}\")\n",
        "      print(f\"\\nTest loss: {test_loss:.4f}, Test acc: {test_acc:.4f}\")\n",
        "\n",
        "\n",
        "  timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "  model_save_path = f\"deepfake_detect_model_{timestamp}.pth\"\n",
        "  torch.save(model_0.state_dict(), model_save_path)\n",
        "  print(f\"Model saved to {model_save_path}\")\n",
        "\n",
        "  # Print out what's happening\n",
        "  print(f\"Train loss: {train_loss:.4f} | Train acc: {train_acc*100:.4f}% | Test loss: {test_loss:.4f} | Test acc: {test_acc*100:.4f}%\")\n",
        "\n",
        "\n",
        "# Calculate training time\n",
        "train_time_end_on_cpu = timer()\n",
        "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
        "                                            end=train_time_end_on_cpu,\n",
        "                                            device=str(next(model_0.parameters()).device))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print out AUC, accuracy, F1 score, precision and recall\n",
        "\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
        "import torch\n",
        "\n",
        "# Assuming you have y_test and test_pred_class from your existing code\n",
        "# Example:\n",
        "# y_test = torch.tensor([0, 1, 0, 1, 0])  # True labels\n",
        "# test_pred_class = torch.tensor([0, 1, 1, 0, 0]) # Predicted labels\n",
        "\n",
        "\n",
        "# ... (your existing code) ...\n",
        "\n",
        "### Testing\n",
        "test_loss, correct_predictions, total_predictions = 0, 0, 0\n",
        "real_as_real, real_as_fake, fake_as_real, fake_as_fake = 0, 0, 0, 0\n",
        "all_y_true = []\n",
        "all_y_pred = []\n",
        "\n",
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "    for i, (X_test, y_test) in enumerate(test_dataloader):\n",
        "        # ... (your existing code) ...\n",
        "\n",
        "        # Store true and predicted labels for metric calculations\n",
        "          all_y_true.extend(y_test.cpu().numpy())\n",
        "          all_y_pred.extend(test_pred_class.cpu().numpy())\n",
        "\n",
        "\n",
        "    # Calculate the test loss average per batch\n",
        "    test_loss /= len(test_dataloader)\n",
        "\n",
        "    # Calculate the test accuracy\n",
        "    #test_acc = correct_predictions / total_predictions\n",
        "    test_acc = (real_as_real + fake_as_fake) / (real_as_real + real_as_fake + fake_as_real + fake_as_fake)\n",
        "\n",
        "    # Calculate evaluation metrics using sklearn\n",
        "    auc = roc_auc_score(all_y_true, all_y_pred)\n",
        "    accuracy = accuracy_score(all_y_true, all_y_pred)\n",
        "    f1 = f1_score(all_y_true, all_y_pred)\n",
        "    precision = precision_score(all_y_true, all_y_pred)\n",
        "    recall = recall_score(all_y_true, all_y_pred)\n",
        "\n",
        "    print(f\"AUC: {auc:.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "    # ... (rest of your existing code) ..."
      ],
      "metadata": {
        "id": "HxP4dPyuI77C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wefLEufDR8nN"
      },
      "outputs": [],
      "source": [
        "#from datetime import datetime\n",
        "#model_save_path = f\"deepfake_detect_model_20250110_201404.pth\"\n",
        "\n",
        "# Load the trained model\n",
        "#loaded_model = DeepFakeDetectV0(output_shape=1)\n",
        "#loaded_model.load_state_dict(torch.load(model_save_path))\n",
        "#loaded_model.to(device)\n",
        "#print(\"Model loaded successfully\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UttqvPsFR8nO"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "model_save_path = f\"deepfake_detect_model_20250112_122939.pth\"\n",
        "\n",
        "# Load the trained model\n",
        "loaded_model = DeepFakeDetectV0(output_shape=1)\n",
        "loaded_model.load_state_dict(torch.load(model_save_path))\n",
        "loaded_model.to(device)\n",
        "print(\"Model loaded successfully\")\n",
        "\n",
        "model_0 = loaded_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxHrw7PxR8nO"
      },
      "outputs": [],
      "source": [
        "### Testing\n",
        "test_loss, correct_predictions, total_predictions = 0, 0, 0\n",
        "real_as_real, real_as_fake, fake_as_real, fake_as_fake = 0, 0, 0, 0\n",
        "model_0.eval()\n",
        "with torch.inference_mode():\n",
        "    for i, (X_test, y_test) in enumerate(test_dataloader):\n",
        "        # Put data to target device\n",
        "        X_test, y_test = X_test.to(device), y_test.float().to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        test_pred = model_0(X_test).squeeze()\n",
        "\n",
        "        # 2. Calculate loss (accumulatively)\n",
        "        test_loss += loss_fn(test_pred, y_test.float()).item()\n",
        "\n",
        "        # 3. Calculate accuracy\n",
        "        test_pred_class = torch.round(torch.sigmoid(test_pred))\n",
        "        correct_predictions += (test_pred_class.view(-1) == y_test).sum().item()\n",
        "        total_predictions += len(y_test)\n",
        "\n",
        "        # Print image names and predictions\n",
        "        for j in range(len(X_test)):\n",
        "            image_index = i * test_dataloader.batch_size + j\n",
        "            image_name = test_dataloader.dataset.data[image_index][0]\n",
        "            true_label = test_dataloader.dataset.data[image_index][1]\n",
        "            predicted_label = test_pred_class[j].item()\n",
        "            print(f\"Image: {image_name}, True Label: {true_label}, Predicted Label: {type(predicted_label)}\")\n",
        "            #print(f\"Image: {image_name}, True Label: {classes[int(true_label)]}, Predicted Label: {classes[int(predicted_label)]}\")\n",
        "\n",
        "            if true_label == 1 and predicted_label == 1:\n",
        "                real_as_real += 1\n",
        "            elif true_label == 1 and predicted_label == 0:\n",
        "                real_as_fake += 1\n",
        "            elif true_label == 0 and predicted_label == 1:\n",
        "                fake_as_real += 1\n",
        "            elif true_label == 0 and predicted_label == 0:\n",
        "                fake_as_fake += 1\n",
        "            #print(real_as_real, real_as_fake, fake_as_real, fake_as_fake)\n",
        "\n",
        "    # Calculate the test loss average per batch\n",
        "    test_loss /= len(test_dataloader)\n",
        "\n",
        "    # Calculate the test accuracy\n",
        "    #test_acc = correct_predictions / total_predictions\n",
        "    #test_acc = (real_as_real + fake_as_fake) / (real_as_real + real_as_fake + fake_as_real + fake_as_fake)\n",
        "    print(f\"Real images identified as real: {real_as_real}\")\n",
        "    print(f\"Real images identified as fake: {real_as_fake}\")\n",
        "    print(f\"Fake images identified as real: {fake_as_real}\")\n",
        "    print(f\"Fake images identified as fake: {fake_as_fake}\")\n",
        "    print(f\"\\nReal images Total: {real_as_real + real_as_fake} | Fake images Total: {fake_as_real + fake_as_fake}\")\n",
        "    print(f\"\\nTest loss: {test_loss:.4f}, Test acc: {test_acc:.4f}\")\n",
        "\n",
        "# Print out what's happening\n",
        "print(f\"Test loss: {test_loss:.4f}, Test acc: {test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LDecPm8R8nP"
      },
      "outputs": [],
      "source": [
        "model_0.state_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMzSlVDzR8nP"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xk7gWOmCR8nQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "084df3c94bde4e5c85fdb93d5cfd38f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b6dd921cf7f41ec862b99dd1addd242": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "125da04131e84e81bd01f7bf993a846b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13096578798942079abe7138af80f6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5650194f9174481185ea9aa6d0ec2d84",
              "IPY_MODEL_18163ba627284ed083ec5bfd7b60d839",
              "IPY_MODEL_3237bdbd33414cfd9c2d51ba5ebd8969"
            ],
            "layout": "IPY_MODEL_17317583e5b54db5b44d2c1b9300f4a6"
          }
        },
        "17317583e5b54db5b44d2c1b9300f4a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18163ba627284ed083ec5bfd7b60d839": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81e21ea4dbf84848a518aeb5ce7acfd6",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a116fe516044870a5c85e6850811342",
            "value": 1
          }
        },
        "1a116fe516044870a5c85e6850811342": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a6428c89e204c85972fdbb89154fba6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b49379076ed41f6834a2f2b359e0a13",
            "placeholder": "​",
            "style": "IPY_MODEL_ce32a36c71284ea3ba4196dfdee638ac",
            "value": " 833/3125 [04:58&lt;13:44,  2.78it/s]"
          }
        },
        "265827331d104b39aa47a120b7208088": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a51f694453844878627a447b62f7a3b",
            "max": 3125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aaaeaec4d0594b73a46fb923228b93dd",
            "value": 3125
          }
        },
        "2ebd67217b60454e868aa09039429f0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30f59b7f6ec6415696f0d3ac4b104e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c50633a05acb43299cf6059ad5a37d2f",
            "max": 3125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b6dd921cf7f41ec862b99dd1addd242",
            "value": 833
          }
        },
        "3237bdbd33414cfd9c2d51ba5ebd8969": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_509f9993a8b641849c644ff9edad1d48",
            "placeholder": "​",
            "style": "IPY_MODEL_7cf4e17cad5a4e47b7e3ab2c9edcceb3",
            "value": " 1/30 [19:47&lt;9:34:04, 1187.74s/it]"
          }
        },
        "3b49379076ed41f6834a2f2b359e0a13": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "509f9993a8b641849c644ff9edad1d48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "517fd7fc718d47a8be7cd0da0b362669": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87ecee2159974eca9572a80a4ee2086e",
              "IPY_MODEL_265827331d104b39aa47a120b7208088",
              "IPY_MODEL_6a99639681e84660b36b22a2aae1606c"
            ],
            "layout": "IPY_MODEL_9bba19571fc74362b9eba466624aef6e"
          }
        },
        "5650194f9174481185ea9aa6d0ec2d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68747309c2534f8bbb40c15ec7f4b661",
            "placeholder": "​",
            "style": "IPY_MODEL_d410aacb950449118ec6b214c49f9e22",
            "value": "  3%"
          }
        },
        "5ca7b95912da463b9e246f3ba0b218c0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d6d3797d6c04b698b67dffb5026e70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ca7b95912da463b9e246f3ba0b218c0",
            "placeholder": "​",
            "style": "IPY_MODEL_084df3c94bde4e5c85fdb93d5cfd38f4",
            "value": " 27%"
          }
        },
        "68747309c2534f8bbb40c15ec7f4b661": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a99639681e84660b36b22a2aae1606c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ebd67217b60454e868aa09039429f0c",
            "placeholder": "​",
            "style": "IPY_MODEL_a9f963f0bd464dcab33f2d1ed44b4805",
            "value": " 3125/3125 [19:24&lt;00:00,  2.71it/s]"
          }
        },
        "6dc2caa925aa41d583810adaf9a604ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d6d3797d6c04b698b67dffb5026e70a",
              "IPY_MODEL_30f59b7f6ec6415696f0d3ac4b104e23",
              "IPY_MODEL_1a6428c89e204c85972fdbb89154fba6"
            ],
            "layout": "IPY_MODEL_e90707b157cd4a08aa0ab9a2b19fc119"
          }
        },
        "7cf4e17cad5a4e47b7e3ab2c9edcceb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81e21ea4dbf84848a518aeb5ce7acfd6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87ecee2159974eca9572a80a4ee2086e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92f6061a150b4cfd8446d12e1ab7771a",
            "placeholder": "​",
            "style": "IPY_MODEL_125da04131e84e81bd01f7bf993a846b",
            "value": "100%"
          }
        },
        "8a51f694453844878627a447b62f7a3b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92f6061a150b4cfd8446d12e1ab7771a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bba19571fc74362b9eba466624aef6e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9f963f0bd464dcab33f2d1ed44b4805": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aaaeaec4d0594b73a46fb923228b93dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c50633a05acb43299cf6059ad5a37d2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce32a36c71284ea3ba4196dfdee638ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d410aacb950449118ec6b214c49f9e22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e90707b157cd4a08aa0ab9a2b19fc119": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}