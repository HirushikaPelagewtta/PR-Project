{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HirushikaPelagewtta/PR-Project/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3472831"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.datasets import EMNIST\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cf82d7d"
      },
      "source": [
        "## Load the emnist dataset\n",
        "Download and load the EMNIST dataset using torchvision's `datasets` module.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13f784b0",
        "outputId": "733b26f5-0746-4f9a-e2e8-d6333f15e163",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_root = './data'\n",
        "os.makedirs(data_root, exist_ok=True)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "emnist_dataset = EMNIST(root=data_root, split='mnist', download=True, transform=transform)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 562M/562M [00:02<00:00, 242MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "453032dc"
      },
      "source": [
        "### Visualize a few images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "6e1c3c41",
        "outputId": "7a5cdcf3-c389-45c0-fbba-84886cb38416"
      },
      "source": [
        "fix_emnist = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: torch.rot90(x, -1, [1, 2])),\n",
        "    transforms.Lambda(lambda x: torch.flip(x, [2]))\n",
        "])\n",
        "\n",
        "emnist_dataset_viz = EMNIST(\n",
        "    root=data_root, split='mnist', download=True, transform=fix_emnist\n",
        ")\n",
        "\n",
        "fig, axes = plt.subplots(2, 5, figsize=(10, 4))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i in range(10):\n",
        "    img, label = emnist_dataset_viz[i]\n",
        "    axes[i].imshow(img.squeeze(), cmap='gray')\n",
        "    axes[i].set_title(f'Label: {label}')\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a seed for reproducibility\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Define the split ratios (e.g., 70% train, 15% validation, 15% test)\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "# Calculate the number of samples for each split\n",
        "total_samples = len(emnist_dataset)\n",
        "train_samples = int(total_samples * train_ratio)\n",
        "val_samples = int(total_samples * val_ratio)\n",
        "test_samples = total_samples - train_samples - val_samples # Ensure all samples are included\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    emnist_dataset,\n",
        "    [train_samples, val_samples, test_samples],\n",
        "    generator=torch.Generator().manual_seed(seed) # Use the same seed for the generator\n",
        ")\n",
        "\n",
        "print(f\"Training dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8D2fNlJl175k",
        "outputId": "19be11c1-a0ab-49f5-d2d2-dcfbac815476"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset size: 42000\n",
            "Validation dataset size: 9000\n",
            "Test dataset size: 9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUxsNZ5-M4cT",
        "outputId": "e0553d3f-01b2-4c37-bf19-b20daba79c9c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "xCf3xRqpPQIx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build CNN Model"
      ],
      "metadata": {
        "id": "lbqhd04pPVV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCNN(nn.Module):\n",
        "  def __init__(self, num_classes=10):\n",
        "    super(CustomCNN, self).__init__()\n",
        "\n",
        "    # Convolutional layers\n",
        "    self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "    self.relu2 = nn.ReLU()\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    # Fully connected layers\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "    self.relu3 = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(0.5)\n",
        "    self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "        # Conv block 1\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        # Conv block 2\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "7Gxvf8gEPXcw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "i34H8hk2RDN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Statistics\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "aaC0FpqnREvF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, val_loader, criterion, device):\n",
        "    \"\"\"Validate the model\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(val_loader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "xV6-ZkKmTOPo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer,\n",
        "                num_epochs, device):\n",
        "    \"\"\"Complete training loop\"\"\"\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion,\n",
        "                                           optimizer, device)\n",
        "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "        print('-' * 60)\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs"
      ],
      "metadata": {
        "id": "U0K-WOEETUgP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer Comparison"
      ],
      "metadata": {
        "id": "rdnxQtv4TWLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_learning_rate(model, train_loader, device, lr_min=1e-6, lr_max=1e-1):\n",
        "    \"\"\"\n",
        "    Simple learning rate finder (optional utility)\n",
        "    Trains for one epoch with exponentially increasing learning rate\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr_min)\n",
        "\n",
        "    lrs = []\n",
        "    losses = []\n",
        "\n",
        "    lr_mult = (lr_max / lr_min) ** (1/len(train_loader))\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        lrs.append(optimizer.param_groups[0]['lr'])\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # Update learning rate\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] *= lr_mult\n",
        "\n",
        "        if loss.item() > 4 * min(losses):  # Stop if loss explodes\n",
        "            break\n",
        "\n",
        "    return lrs, losses"
      ],
      "metadata": {
        "id": "R_f2tonTTVsw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_optimizers():\n",
        "    results = {}\n",
        "    num_epochs = 20\n",
        "\n",
        "    # 1. Adam Optimizer\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Training with Adam Optimizer\")\n",
        "    print(\"=\"*60)\n",
        "    model_adam = CustomCNN(num_classes=10).to(device)\n",
        "    optimizer_adam = optim.Adam(model_adam.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_losses_adam, val_losses_adam, train_accs_adam, val_accs_adam = \\\n",
        "        train_model(model_adam, train_loader, val_loader, criterion,\n",
        "                   optimizer_adam, num_epochs, device)\n",
        "\n",
        "    results['Adam'] = {\n",
        "        'model': model_adam,\n",
        "        'train_losses': train_losses_adam,\n",
        "        'val_losses': val_losses_adam,\n",
        "        'train_accs': train_accs_adam,\n",
        "        'val_accs': val_accs_adam\n",
        "    }\n",
        "\n",
        "    # 2. SGD (Standard)\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Training with Standard SGD\")\n",
        "    print(\"=\"*60)\n",
        "    model_sgd = CustomCNN(num_classes=10).to(device)\n",
        "    optimizer_sgd = optim.SGD(model_sgd.parameters(), lr=0.01)\n",
        "\n",
        "    train_losses_sgd, val_losses_sgd, train_accs_sgd, val_accs_sgd = \\\n",
        "        train_model(model_sgd, train_loader, val_loader, criterion,\n",
        "                   optimizer_sgd, num_epochs, device)\n",
        "\n",
        "    results['SGD'] = {\n",
        "        'model': model_sgd,\n",
        "        'train_losses': train_losses_sgd,\n",
        "        'val_losses': val_losses_sgd,\n",
        "        'train_accs': train_accs_sgd,\n",
        "        'val_accs': val_accs_sgd\n",
        "    }\n",
        "\n",
        "    # 3. SGD with Momentum\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Training with SGD + Momentum\")\n",
        "    print(\"=\"*60)\n",
        "    model_sgd_momentum = CustomCNN(num_classes=10).to(device)\n",
        "    optimizer_sgd_momentum = optim.SGD(model_sgd_momentum.parameters(),\n",
        "                                       lr=0.01, momentum=0.9)\n",
        "\n",
        "    train_losses_momentum, val_losses_momentum, train_accs_momentum, val_accs_momentum = \\\n",
        "        train_model(model_sgd_momentum, train_loader, val_loader, criterion,\n",
        "                   optimizer_sgd_momentum, num_epochs, device)\n",
        "\n",
        "    results['SGD_Momentum'] = {\n",
        "        'model': model_sgd_momentum,\n",
        "        'train_losses': train_losses_momentum,\n",
        "        'val_losses': val_losses_momentum,\n",
        "        'train_accs': train_accs_momentum,\n",
        "        'val_accs': val_accs_momentum\n",
        "    }\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "9HUPYONlTfBY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "to8WEUJ3TnAw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, device):\n",
        "    \"\"\"\n",
        "    Question 12: Model Evaluation\n",
        "    Computes: Accuracy, Confusion Matrix, Precision, Recall\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    accuracy = 100. * correct / total\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # Classification Report (includes precision, recall, F1-score)\n",
        "    report = classification_report(all_labels, all_preds,\n",
        "                                   target_names=[str(i) for i in range(10)])\n",
        "\n",
        "    return accuracy, cm, report"
      ],
      "metadata": {
        "id": "WGR5Q6M7ToGt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_curves(results):\n",
        "    \"\"\"Plot training and validation curves for all optimizers\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    # Loss curves\n",
        "    for name, data in results.items():\n",
        "        axes[0, 0].plot(data['train_losses'], label=f'{name} Train')\n",
        "        axes[0, 1].plot(data['val_losses'], label=f'{name} Val')\n",
        "\n",
        "    axes[0, 0].set_title('Training Loss')\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Loss')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True)\n",
        "\n",
        "    axes[0, 1].set_title('Validation Loss')\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Loss')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True)\n",
        "\n",
        "    # Accuracy curves\n",
        "    for name, data in results.items():\n",
        "        axes[1, 0].plot(data['train_accs'], label=f'{name} Train')\n",
        "        axes[1, 1].plot(data['val_accs'], label=f'{name} Val')\n",
        "\n",
        "    axes[1, 0].set_title('Training Accuracy')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('Accuracy (%)')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True)\n",
        "\n",
        "    axes[1, 1].set_title('Validation Accuracy')\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].set_ylabel('Accuracy (%)')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_curves.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "yF8bEIllTsbo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, title='Confusion Matrix'):\n",
        "    \"\"\"Plot confusion matrix\"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.savefig(f'{title.replace(\" \", \"_\")}.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "wzfEPD38TxC3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Train and compare optimizers\n",
        "    print(\"Starting optimizer comparison...\")\n",
        "    results = compare_optimizers()\n",
        "\n",
        "    # Plot training curves\n",
        "    print(\"\\nPlotting training curves...\")\n",
        "    plot_training_curves(results)\n",
        "\n",
        "    # Evaluate each model on test set\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"FINAL EVALUATION ON TEST SET\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for name, data in results.items():\n",
        "        print(f\"\\n{name} Optimizer:\")\n",
        "        accuracy, cm, report = evaluate_model(data['model'], test_loader, device)\n",
        "        print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "        print(\"\\nClassification Report:\")\n",
        "        print(report)\n",
        "        plot_confusion_matrix(cm, title=f'Confusion Matrix - {name}')\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Training Complete! Check saved plots.\")\n",
        "    print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgsUo3qCT1UE",
        "outputId": "bfc4ac98-bc7c-43c7-e0e4-8404b1a99abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting optimizer comparison...\n",
            "\n",
            "============================================================\n",
            "Training with Adam Optimizer\n",
            "============================================================\n",
            "Epoch [1/20]\n",
            "Train Loss: 0.2478, Train Acc: 92.44%\n",
            "Val Loss: 0.0567, Val Acc: 98.33%\n",
            "------------------------------------------------------------\n",
            "Epoch [2/20]\n",
            "Train Loss: 0.0873, Train Acc: 97.49%\n",
            "Val Loss: 0.0415, Val Acc: 98.69%\n",
            "------------------------------------------------------------\n",
            "Epoch [3/20]\n",
            "Train Loss: 0.0633, Train Acc: 98.13%\n",
            "Val Loss: 0.0363, Val Acc: 98.87%\n",
            "------------------------------------------------------------\n",
            "Epoch [4/20]\n",
            "Train Loss: 0.0521, Train Acc: 98.45%\n",
            "Val Loss: 0.0330, Val Acc: 99.01%\n",
            "------------------------------------------------------------\n",
            "Epoch [5/20]\n",
            "Train Loss: 0.0462, Train Acc: 98.68%\n",
            "Val Loss: 0.0357, Val Acc: 98.90%\n",
            "------------------------------------------------------------\n",
            "Epoch [6/20]\n",
            "Train Loss: 0.0367, Train Acc: 98.88%\n",
            "Val Loss: 0.0332, Val Acc: 99.11%\n",
            "------------------------------------------------------------\n",
            "Epoch [7/20]\n",
            "Train Loss: 0.0338, Train Acc: 99.00%\n",
            "Val Loss: 0.0325, Val Acc: 99.00%\n",
            "------------------------------------------------------------\n",
            "Epoch [8/20]\n",
            "Train Loss: 0.0286, Train Acc: 99.11%\n",
            "Val Loss: 0.0287, Val Acc: 99.23%\n",
            "------------------------------------------------------------\n",
            "Epoch [9/20]\n",
            "Train Loss: 0.0266, Train Acc: 99.16%\n",
            "Val Loss: 0.0373, Val Acc: 99.18%\n",
            "------------------------------------------------------------\n",
            "Epoch [10/20]\n",
            "Train Loss: 0.0269, Train Acc: 99.22%\n",
            "Val Loss: 0.0314, Val Acc: 99.16%\n",
            "------------------------------------------------------------\n",
            "Epoch [11/20]\n",
            "Train Loss: 0.0209, Train Acc: 99.32%\n",
            "Val Loss: 0.0367, Val Acc: 99.23%\n",
            "------------------------------------------------------------\n",
            "Epoch [12/20]\n",
            "Train Loss: 0.0200, Train Acc: 99.35%\n",
            "Val Loss: 0.0388, Val Acc: 99.19%\n",
            "------------------------------------------------------------\n",
            "Epoch [13/20]\n",
            "Train Loss: 0.0167, Train Acc: 99.45%\n",
            "Val Loss: 0.0411, Val Acc: 99.07%\n",
            "------------------------------------------------------------\n",
            "Epoch [14/20]\n",
            "Train Loss: 0.0167, Train Acc: 99.49%\n",
            "Val Loss: 0.0386, Val Acc: 99.20%\n",
            "------------------------------------------------------------\n",
            "Epoch [15/20]\n",
            "Train Loss: 0.0162, Train Acc: 99.51%\n",
            "Val Loss: 0.0386, Val Acc: 99.21%\n",
            "------------------------------------------------------------\n",
            "Epoch [16/20]\n",
            "Train Loss: 0.0152, Train Acc: 99.45%\n",
            "Val Loss: 0.0372, Val Acc: 99.30%\n",
            "------------------------------------------------------------\n",
            "Epoch [17/20]\n",
            "Train Loss: 0.0135, Train Acc: 99.57%\n",
            "Val Loss: 0.0451, Val Acc: 99.17%\n",
            "------------------------------------------------------------\n",
            "Epoch [18/20]\n",
            "Train Loss: 0.0140, Train Acc: 99.53%\n",
            "Val Loss: 0.0461, Val Acc: 99.20%\n",
            "------------------------------------------------------------\n",
            "Epoch [19/20]\n",
            "Train Loss: 0.0126, Train Acc: 99.56%\n",
            "Val Loss: 0.0370, Val Acc: 99.32%\n",
            "------------------------------------------------------------\n",
            "Epoch [20/20]\n",
            "Train Loss: 0.0111, Train Acc: 99.65%\n",
            "Val Loss: 0.0458, Val Acc: 99.20%\n",
            "------------------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "Training with Standard SGD\n",
            "============================================================\n",
            "Epoch [1/20]\n",
            "Train Loss: 0.6638, Train Acc: 79.59%\n",
            "Val Loss: 0.2428, Val Acc: 92.59%\n",
            "------------------------------------------------------------\n",
            "Epoch [2/20]\n",
            "Train Loss: 0.2754, Train Acc: 91.62%\n",
            "Val Loss: 0.1915, Val Acc: 94.57%\n",
            "------------------------------------------------------------\n",
            "Epoch [3/20]\n",
            "Train Loss: 0.2091, Train Acc: 93.61%\n",
            "Val Loss: 0.1375, Val Acc: 95.90%\n",
            "------------------------------------------------------------\n",
            "Epoch [4/20]\n",
            "Train Loss: 0.1724, Train Acc: 94.85%\n",
            "Val Loss: 0.1135, Val Acc: 96.57%\n",
            "------------------------------------------------------------\n",
            "Epoch [5/20]\n",
            "Train Loss: 0.1433, Train Acc: 95.73%\n",
            "Val Loss: 0.1107, Val Acc: 96.70%\n",
            "------------------------------------------------------------\n",
            "Epoch [6/20]\n",
            "Train Loss: 0.1225, Train Acc: 96.42%\n",
            "Val Loss: 0.0856, Val Acc: 97.36%\n",
            "------------------------------------------------------------\n",
            "Epoch [7/20]\n",
            "Train Loss: 0.1099, Train Acc: 96.71%\n",
            "Val Loss: 0.0741, Val Acc: 97.76%\n",
            "------------------------------------------------------------\n",
            "Epoch [8/20]\n",
            "Train Loss: 0.0972, Train Acc: 97.06%\n",
            "Val Loss: 0.0689, Val Acc: 98.04%\n",
            "------------------------------------------------------------\n",
            "Epoch [9/20]\n",
            "Train Loss: 0.0880, Train Acc: 97.44%\n",
            "Val Loss: 0.0711, Val Acc: 97.96%\n",
            "------------------------------------------------------------\n",
            "Epoch [10/20]\n",
            "Train Loss: 0.0806, Train Acc: 97.68%\n",
            "Val Loss: 0.0675, Val Acc: 97.89%\n",
            "------------------------------------------------------------\n",
            "Epoch [11/20]\n",
            "Train Loss: 0.0758, Train Acc: 97.77%\n",
            "Val Loss: 0.0580, Val Acc: 98.26%\n",
            "------------------------------------------------------------\n",
            "Epoch [12/20]\n",
            "Train Loss: 0.0701, Train Acc: 97.92%\n",
            "Val Loss: 0.0510, Val Acc: 98.53%\n",
            "------------------------------------------------------------\n",
            "Epoch [13/20]\n",
            "Train Loss: 0.0650, Train Acc: 98.04%\n",
            "Val Loss: 0.0555, Val Acc: 98.36%\n",
            "------------------------------------------------------------\n",
            "Epoch [14/20]\n",
            "Train Loss: 0.0613, Train Acc: 98.22%\n",
            "Val Loss: 0.0564, Val Acc: 98.29%\n",
            "------------------------------------------------------------\n",
            "Epoch [15/20]\n",
            "Train Loss: 0.0579, Train Acc: 98.29%\n",
            "Val Loss: 0.0491, Val Acc: 98.44%\n",
            "------------------------------------------------------------\n",
            "Epoch [16/20]\n",
            "Train Loss: 0.0546, Train Acc: 98.38%\n",
            "Val Loss: 0.0456, Val Acc: 98.64%\n",
            "------------------------------------------------------------\n",
            "Epoch [17/20]\n",
            "Train Loss: 0.0529, Train Acc: 98.41%\n",
            "Val Loss: 0.0440, Val Acc: 98.69%\n",
            "------------------------------------------------------------\n",
            "Epoch [18/20]\n",
            "Train Loss: 0.0501, Train Acc: 98.44%\n",
            "Val Loss: 0.0433, Val Acc: 98.73%\n",
            "------------------------------------------------------------\n",
            "Epoch [19/20]\n",
            "Train Loss: 0.0494, Train Acc: 98.54%\n",
            "Val Loss: 0.0415, Val Acc: 98.81%\n",
            "------------------------------------------------------------\n",
            "Epoch [20/20]\n",
            "Train Loss: 0.0477, Train Acc: 98.51%\n",
            "Val Loss: 0.0410, Val Acc: 98.81%\n",
            "------------------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "Training with SGD + Momentum\n",
            "============================================================\n",
            "Epoch [1/20]\n",
            "Train Loss: 0.3313, Train Acc: 89.56%\n",
            "Val Loss: 0.0706, Val Acc: 97.81%\n",
            "------------------------------------------------------------\n",
            "Epoch [2/20]\n",
            "Train Loss: 0.1047, Train Acc: 96.97%\n",
            "Val Loss: 0.0525, Val Acc: 98.39%\n",
            "------------------------------------------------------------\n",
            "Epoch [3/20]\n",
            "Train Loss: 0.0762, Train Acc: 97.75%\n",
            "Val Loss: 0.0438, Val Acc: 98.64%\n",
            "------------------------------------------------------------\n",
            "Epoch [4/20]\n",
            "Train Loss: 0.0608, Train Acc: 98.24%\n",
            "Val Loss: 0.0427, Val Acc: 98.68%\n",
            "------------------------------------------------------------\n",
            "Epoch [5/20]\n",
            "Train Loss: 0.0544, Train Acc: 98.42%\n",
            "Val Loss: 0.0354, Val Acc: 98.94%\n",
            "------------------------------------------------------------\n",
            "Epoch [6/20]\n",
            "Train Loss: 0.0456, Train Acc: 98.64%\n",
            "Val Loss: 0.0418, Val Acc: 98.81%\n",
            "------------------------------------------------------------\n",
            "Epoch [7/20]\n",
            "Train Loss: 0.0406, Train Acc: 98.72%\n",
            "Val Loss: 0.0340, Val Acc: 99.02%\n",
            "------------------------------------------------------------\n",
            "Epoch [8/20]\n",
            "Train Loss: 0.0365, Train Acc: 98.90%\n",
            "Val Loss: 0.0328, Val Acc: 99.13%\n",
            "------------------------------------------------------------\n",
            "Epoch [9/20]\n",
            "Train Loss: 0.0316, Train Acc: 99.01%\n",
            "Val Loss: 0.0328, Val Acc: 99.18%\n",
            "------------------------------------------------------------\n",
            "Epoch [10/20]\n",
            "Train Loss: 0.0277, Train Acc: 99.13%\n",
            "Val Loss: 0.0325, Val Acc: 99.19%\n",
            "------------------------------------------------------------\n",
            "Epoch [11/20]\n",
            "Train Loss: 0.0252, Train Acc: 99.15%\n",
            "Val Loss: 0.0400, Val Acc: 99.11%\n",
            "------------------------------------------------------------\n",
            "Epoch [12/20]\n",
            "Train Loss: 0.0250, Train Acc: 99.18%\n",
            "Val Loss: 0.0351, Val Acc: 99.04%\n",
            "------------------------------------------------------------\n",
            "Epoch [13/20]\n",
            "Train Loss: 0.0228, Train Acc: 99.31%\n",
            "Val Loss: 0.0352, Val Acc: 99.19%\n",
            "------------------------------------------------------------\n",
            "Epoch [14/20]\n",
            "Train Loss: 0.0208, Train Acc: 99.33%\n",
            "Val Loss: 0.0321, Val Acc: 99.23%\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}